\documentclass[a4paper,twocolumn]{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage{titlesec}
\usepackage{amsmath}

\titleformat*{\section}{\large\bfseries}
\titleformat*{\subsection}{\normalsize\bfseries}
\titleformat*{\subsubsection}{\small\bfseries}

\newcommand{\D}{\mathcal{D}}
\newcommand{\T}{\mathcal{T}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}

\DeclareMathOperator*{\argmin}{arg\,min}

\title{A Survey on Transfer Learning $-$ summary}
\author{Matěj Nikl}

\begin{document}
\maketitle
As the title suggests, this paper focuses on transfer learning.
A few definitions:

\begin{itemize}
    \item a \textbf{Domain} $\D = \{\X, P(X)\}$
        \begin{itemize}
            \item a feature space $\X$
            \item a marginal probability distribution $P(X)$, where $X = \{x_1, \ldots, x_n\} \in \X$
            \item $\D_S$, $\D_T$ $-$ source and target domains
        \end{itemize}
    \item a \textbf{Task} $\T = \{\Y, f(\cdot)\}$ (given a domain $\D$)
        \begin{itemize}
            \item a label space $\Y$
            \item an objective predictive function $f(\cdot)$, which is not observed but can be learned from the training data
            \item $\T_S$, $\T_T$ $-$ source and target tasks
        \end{itemize}
    \item \textbf{Training Data} consist of pairs $\{x_i, y_i\}$
        \begin{itemize}
            \item $x_i \in \X$ and $y_i \in \Y$
            \item $D_S$, $D_T$ $-$ source and target data with $n_S$ and $n_T$ instances each
            \item in most cases $0 \le n_T \ll n_S$
        \end{itemize}
    \item \textbf{Transfer Learning} $-$ given $\D_S$, $\T_S$, $\D_T$ and $\T_T$, transfer learning aims to help improve the learning of the target predictive function $f_T(\cdot)$ in $\D_T$ using the knowledge in $\D_S$ and $\T_S$, where $\D_S \ne \D_T$, or $\T_S \ne \T_T$
        \begin{itemize}
            \item when $\D_S = \D_T$ and $\T_S = \T_T$, the learning problem becomes a traditional machine learning problem
        \end{itemize}
\end{itemize}

In other words, transfer learning aims to extract a knowledge from one or more source tasks (and their domains) and applies the knowledge to a target task.

One should not confuse transfer learning with multi-task learning $-$ multi-task learning tries to learn all of the source and target tasks simultaneously (thus treating them all equally), transfer learning cares the most about the target task.

There are three main research issues:
\begin{enumerate}
    \item \textbf{What} to transfer $-$ which part of the knowledge can be transferred across domains or tasks $-$ some of it may be specific for individual domains or tasks, some may be common
    \item \textbf{How} to transfer $-$ learning algorithms need to be developed to transfer the knowledge
    \item \textbf{When} to transfer $-$ in which situations should transferring be done as well as in which it should not be done $-$ when source and target domains are not related to each other, transferring the knowledge may even hurt the performance $-$ a phenomenon called \textit{negative transfer}
\end{enumerate}

Based on the definition of transfer learning, its relationship can be summarized into three sub-settings:

\begin{enumerate}
    \item \textbf{Inductive Transfer Learning}
        \begin{itemize}
            \item $\T_S \ne \T_T$
            \item a few labeled data in $\D_T$ are required to \textit{induce} $f_T(\cdot)$ for use in $\D_T$
        \end{itemize}
        Further categorization:
        \begin{enumerate}
            \item A lot of labeled data in $\D_S$ $-$ similar to the multi-task learning
            \item No labeled data in $\D_S$ $-$ similar to the self-taught learning
        \end{enumerate}
    \item \textbf{Transductive Transfer Learning}
        \begin{itemize}
            \item $\D_S \ne \D_T$, $\T_S = \T_T$
            \item A lot of labeled data in $\D_S$, no labeled data in $\D_T$ (thus some unlabeled data in $\D_T$ must be available)
        \end{itemize}
        Further categorization:
        \begin{enumerate}
            \item $\X_S \ne \X_T$
            \item $\X_S = \X_T$, but $P(X_S) \ne P(X_T)$, is related to:
                \begin{itemize}
                    \item domain adaptation for knowledge transfer in text classification
                    \item sample selection bias
                    \item co-variate shift
                \end{itemize}
        \end{enumerate}
    \item \textbf{Unsupervised Transfer Learning}
        \begin{itemize}
            \item $\T_S \ne \T_T$, $\Y_S$ and $\Y_T$ are not observable
            \item different focus $-$ clustering, dimensionality reduction, density estimation
            \item the predicted labels are latent variables, such as clusters or reduced dimensions
        \end{itemize}
\end{enumerate}

Approaches to the above three different settings can be summarized into four cases based on what to transfer:

\begin{enumerate}
    \item \textbf{Instance-based transfer learning} $-$ assumes that certain parts of the data in $\D_S$ can be reused for learning in $\D_T$ by re-weighting or importance sampling
    \item \textbf{Feature-representation-transfer} $-$ learning a ``good'' feature representation for $\D_T$, thus (hopefully) improving the performance significantly
    \item \textbf{Parameter-transfer} $-$ assumes that $\T_S$ and $\T_T$ share some parameters or prior distributions of the hyper-parameters of the models
    \item \textbf{Relational-knowledge-transfer} $-$ assumes that relationship among the data in $\D_S$ and $\D_T$ are similar
\end{enumerate}

\section{Inductive Transfer Learning}
\subsection{Transferring Knowledge of Instances}
$\D_S$ data cannot be used directly, however certain parts possibly can $-$ together with a few labeled data in $\D_T$.

TrAdaBoost boosting algorithm (extension of AdaBoost) addresses this problem, assumes $\X_S = \X_T$ and $\Y_S = \Y_T$, but $P(X_S) \ne P(X_T)$. It iteratively re-weights the $\D_S$ data to reduce the effect of the ``bad'' source data while encourage the ``good'' source data to contribute more for $\D_T$.

There are also other algorithms, e.g. a heuristic method to remove ``misleading'' training examples from $\D_S$ based on the difference between conditional probabilities $P(y_S|x_S)$ and $P(y_T|x_T)$.

\subsection{Transferring Knowledge of Feature Representations}
There are different strategies for different types of $\D_S$ data for finding ``good'' feature representations to minimize domain divergence and classification or regression model error.

If a lot of labeled data in $\D_S$ are available, supervised learning can be used (similar to \textit{common feature learning} in the field of multi-task learning).
Otherwise, unsupervised learning must be used.

\subsubsection{Supervised Feature Construction}
The basic idea is to learn a low-dimensional representation that is shared across related tasks. The learned representation can reduce the classification or regression model error of each task as well. It is learned by solving an optimization problem, which can be transformed into an equivalent convex optimization formulation and thus solved efficiently.
\subsubsection{Unsupervised Feature Construction}
The proposed solution is to apply sparse coding $-$ a unsupervised feature construction method, for learning \textit{higher level} features for transfer learning.
It consists of two (three) steps
\begin{enumerate}
    \item learning higher-level basis vectors $b = \{b_1, b_2, \ldots, b_s\}$
    \item learning higher level features based on the basis vectors $b$
    \item (optional) applying discriminative algorithms to train classification or regression models for use in $\D_T$
\end{enumerate}
\subsection{Transferring Knowledge of Parameters}
Most approaches in this section, like a regularization framework and a hierarchical Bayesian framework are designed to work under multi-task learning, however they can be easily modified for transfer learning by adjusting the weights in the loss functions $-$ for example by assigning a larger weight to the loss function of $\D_T$ (thus making it more important to minimize than the loss function of $\D_S$).

An example for this task is a MT-IVM algorithm, which is based on Gaussian Processes (GP) – it tries to learn parameters of a GP over multiple tasks by sharing the same GP prior.
Similar approach uses free-form covariance matrix over tasks to model inter-task dependencies.

Another approach tries to transfer parameters of SVMs under a regularization framework $-$ separating a parameter $w$ into two terms:
\begin{enumerate}
    \item a common term over tasks
    \item a task-specific term
\end{enumerate}

\subsection{Transferring Relational Knowledge}
Differently from other three contexts, this approach deals with data that are not independent and identically distributed (i.i.d.) (or at least it is not assumed that they are) and can be represented by multiple relations, such as networked data or social network data. Statistical relational learning techniques are proposed to solve these problems.

A \textit{TAMAR} algorithm transfers relational knowledge with Markov Logic Networks (MLNs). MLN uses predicates to represent entities in a relational domain, while their relationships are represented in first-order logic. The idea is that if two domains are related to each other, there may exist mappings to connect entities and their relationships from $\D_S$ to $\D_T$ (e.g. academic domain$-$professor and industrial management domain$-$manager). TAMAR tries to use an MLN learned for $\D_S$ to aid the learning of an MLN for $\D_T$:
\begin{enumerate}
    \item a mapping from a source MLN to $\D_T$ based on weighted pseudo-loglikelihood measure (WPLL) is created
    \item a revision of the mapped structure is done using the \textit{FORTE} algorithm $-$ revising the first order theories
\end{enumerate}
The revised MLN can be used as a relational model for inference or reasoning in $\D_T$.

Another approach on this task is based on a form of second-order Markov logic $-$ it tries to discover structural regularities in $\D_S$ in the form of Markov logic formulas with predicate variables, by instantiating these formulas with predicates from $\D_T$.

\section{Transductive Transfer Learning}
\subsection{Transferring Knowledge of Instances}
Most approaches are motivated by importance sampling. We can learn the optimal parameters $\theta$ by minimizing the empirical risk (ERM):

\[
    \theta = \argmin_{\theta \in \Theta} \sum_{(x,y) \in D_T} P(D_T)l(x, y, \theta)
\]

However, since no labeled data in $D_T$ are observed and $P(D_S) = P(D_T)$, we may simply learn the model:
\[
    \theta = \argmin_{\theta \in \Theta} \sum_{(x,y) \in D_S} P(D_S)l(x, y, \theta)
\]

If $P(D_S) \ne P(D_T)$:

\begin{align*}
    \theta &= \argmin_{\theta \in \Theta} \sum_{(x,y) \in D_S} \frac{P(D_T)}{P(D_S)}P(D_S)l(x, y, \theta) \\
           &\approx \argmin_{\theta \in \Theta} \sum_{i = 1}^{n_S} \frac{P_T(x_{T_i}, y_{T_i})}{P_S(x_{S_i}, y_{S_i})}l(x, y, \theta) \\
           &= \argmin_{\theta \in \Theta} \sum_{i = 1}^{n_S} \frac{P(x_{S_i})}{P(x_{T_i})}l(x, y, \theta)
\end{align*}

Last simplification comes from $P(Y_S|X_S) = P(Y_T|X_T)$, thus the difference between $P(D_S)$ and $P(D_T)$ is caused by $P(X_S)$ and $P(X_T)$, hence the simplification. The remaining problem is the estimation of $\frac{P(x_{S_i})}{P(x_{T_i})}$.

Various ways to estimate the fraction exist. One way is to estimate the terms independently by constructing simple classification problems. The other way is to estimate the probability ratio directly:
\begin{itemize}
    \item by using various classifiers
    \item a kernel-mean matching (KMM) algorithm $-$ matches the means between $D_S$ and $D_T$ in a reproducing-kernel Hilbert space (RKHS), can be rewritten as a quadratic programming (QP) optimization problem, avoids performing density estimation of either $P(x_{S_i})$ or $P(x_{T_I})$, which is difficult when the size of the dataset is small
    \item a Kullback-Leibler divergence (KLIEP) $-$ can estimate the weights of the $D_S$ and thus train models on the re-weighted data to perform model selection automatically using cross-validation
\end{itemize}

\subsection{Transferring Knowledge of Feature Representations}
Most approaches are under unsupervised learning frameworks. A structural correspondence learning (SCL) algorithm is proposed. It makes use of the unlabeled data from $\D_T$ to extract relevant features that may reduce the difference between the domains:
\begin{enumerate}
    \item define a set of $m$ \textit{pivot} features (which are domain specific and depend on prior knowledge) on the unlabeled data from both domains
    \item remove the pivot features from the data and that each as a new label vector
    \item construct $m$ classification problems
    \item by assuming each can be solved by linear classifier, learn a matrix $W = [w_1 w_2 \ldots w_m]$ of parameters
    \item SVD is applied $W = UDV^T$, then $\theta = U_{[1:h,:]}^T$ ($h$ being the number of shared features) is the linear mapping whose rows are the top left singular vectors of $W$.
    \item apply standard discriminative algorithms to the augmented feature vector to build models
\end{enumerate}
The drawback is that the pivot features must be well designed, which is difficult and domain-dependent.

A heuristic for selecting pivot features for natural language processing (NLP) problems exists (e.g. tagging of sentences), the follow-up work proposes using Mutual Information (MI) to choose the pivot features. MI-SCL tries to find some pivot features that have high dependence on the labels in $\D_S$.

In domain adaptation (transfer learning in NLP domain) a kernel-mapping function was proposed $-$ it maps data from both $\D_S$ and $\D_T$ to a high-dimensional feature space, where standard methods are used to train classifiers. However, the constructed mapping function is domain knowledge driven, thus hard to generalize to other domains.

Other approaches include:
\begin{itemize}
    \item a co-clustering based algorithm to propagate the label information across domains
    \item a bridged refinement algorithm $-$ it corrects the labels predicted by a shift-unaware classifier towards a target distribution and takes the mixture distribution of the training and test data as a bridge to better transfer from the training data to the test data
    \item a spectral classification framework, where the objective function is introduced to seek consistency between the in-domain supervision and the out-of-domain intrinsic structure
    \item dimensionality reduction $-$ Maximum Mean Discrepancy Embedding (MMDE) algorithm and more efficient feature extraction algorithm known as Transfer Component Analysis (TCA)
\end{itemize}

\section{Unsupervised Transfer Learning}
A little research work on this setting has been done.

\subsection{Transferring Knowledge of Feature Representations}
Self-taught clustering (STC) algorithm is an instance of unsupervised transfer learning. It aims at clustering a small amount of unlabeled data in $\D_T$ with help of a large amount in the $\D_S$. It tries to learn common feature space across domains. An iterative algorithm is used to solve the optimization function given by STC.

Transferred discriminative analysis (TDA) tries to solve the transfer dimensionality reduction problem. It runs iteratively:
\begin{enumerate}
    \item apply clustering to generate pseudo-class labels for the $D_T$
    \item apply dimensionality reduction methods
\end{enumerate}
to find the best subspace for $D_T$.

\subsection*{Transfer bounds}
It would be very useful to know the ``right'' amount of information to transfer. It has been done using conditional Kolmogorov complexity to measure relatedness between tasks.

Another approach is a graph-based method. It embeds a set of learned source models in a graph using transferability as a metric. Transferring to a new task proceeds by using this graph by mapping the problem into it and learning a function to automatically determine the parameters to transfer.

\end{document}
